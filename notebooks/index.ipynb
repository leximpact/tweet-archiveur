{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Archiveur\n",
    "\n",
    "> This project aim at storing the tweet of all members of the French Parliament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to use tweets to get an idea of the topics of the tweets using NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "TODO : push it to Pipy when :\n",
    "- Rename \"nom\" to name in users\n",
    "- reactivate unit tests (https://docs.github.com/en/actions/guides/creating-postgresql-service-containers)\n",
    "- Made scrapper a Class\n",
    "- Switch to SQL Alchemy\n",
    "- Flake8\n",
    "- Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install tweetarchiveur`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is two class :\n",
    "- A Scrapper() to use the Twitter API\n",
    "- A Database() to store tweets and hastags in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 10:21:59,837 -  tweet-archiveur INFO     Scrapper ready\n",
      "2021-03-22 10:21:59,841 -  tweet-archiveur INFO     Loading database module...\n",
      "2021-03-22 10:21:59,842 -  tweet-archiveur DEBUG    DEBUG : connect(user=tweet_archiveur_user, password=XXXX, host=localhost, port=8479, database=tweet_archiveur, url=None)\n",
      "2021-03-22 10:22:03,915 -  tweet-archiveur INFO     Done scrapping, we got 400 tweets from 2 tweetos.\n"
     ]
    }
   ],
   "source": [
    "from tweet_archiveur.scrapper import Scrapper\n",
    "from tweet_archiveur.database import Database\n",
    "\n",
    "# Force some variable outside Docker\n",
    "from os import environ\n",
    "environ[\"DATABASE_PORT\"] = '8479'\n",
    "environ[\"DATABASE_HOST\"] = 'localhost'\n",
    "environ[\"DATABASE_USER\"] = 'tweet_archiveur_user'\n",
    "environ[\"DATABASE_PASS\"] = '1234leximpact'\n",
    "environ[\"DATABASE_NAME\"] = 'tweet_archiveur'\n",
    "\n",
    "scrapper = Scrapper()\n",
    "df_users = scrapper.get_users_accounts('../tests/sample-users.csv')\n",
    "users_id = df_users.twitter_id.tolist()\n",
    "database = Database()\n",
    "database.create_tables_if_not_exist()\n",
    "database.insert_twitter_users(df_users)\n",
    "scrapper.get_all_tweet_and_store_them(database, users_id[0:2])\n",
    "del database\n",
    "del scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do with it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most used hashtag (per period, per person)\n",
    "- Most/Less active user\n",
    "- Timeline of \n",
    "- NLP Topic detection\n",
    "- Word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexes\n",
    "\n",
    "Exit code :\n",
    "- 1 : Unknown error when storing tweets\n",
    "- 2 : Unknown error getting tweets\n",
    "- 3 : Failed more than 3 consecutive times\n",
    "- 4 : no env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one thing fail no tweet will be saved.\n",
    "\n",
    "status code = 429 : 429 'Too many requests' error is returned when you exceed the maximum number of requests allowed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
